---
title: "Thinking Out Loud on Career Choice"
date: 2023-03-17
---
I'm not sure if I'm a good fit for doing anything with respect to climate change.  I am looking at switching to, 
e.g. AI, or, if not that, then some other EA-aligned thing.
Question 1: Why am I thinking of doing this? Or why do I not really give an ass about what I study now?
Question 2: Why would it be unwise to do this
Question 3: Is my current decision-making algorithm stupid, and if so, how to repair?

Question 1:

I've been studying SET at TU Delft for two years now - I've been reasonably involved in the climate / energy space, enough to get a feel for things.
The primary problem, more important than the rest, is that I don't see a path to impact that uses my comparative advantage.
I've seen friends who have an impressive grasp on analysing tech from the "engineer's perspective" that I thought I could have.
Turns out, this is a skill that I don't, by default, have.  Now I presumably could develop this skill - if I were to, what then?
Do I have any especial insights into energy policy?  None that aren't derived from a paper I've read, or a podcast I've listened to;
furthermore, most of my opinions in this space are opinions for the sake of having them - they're frankly not epistemically honest, and I couldn't make
them be so without a lot of work.

Further, it seems like, if any career is to be high-impact, it would be something like policy - here I may have a relative disadvantage due to my
lack of empathy with other people.  If I were to go the policy-route, I don't know that I could produce anything of value.
On the other hand, the academic route seems pointless too - if technology is already so highly developed that it's macroscale 
predictable (like solar learning-curves), what could I possibly have to add?  Presumably all I could do is step into the middle of the 
process and just help others push the boulder up....

Then, there's "politics", but I think the appeal of this to me is the appeal of being a character people could elect - not even power, but self-image.
While it would be 'cute' to become a congressman, would I be willing to sacrifice for it?  Probably not much.  Would I bring anything unique to the table?
Maybe, but to the extent that I do, it would be just smuggling in other peoples' ideas to political respectability; and to the extent that politicians
are ostensibly bound by their constituents, it doesn't seem like I'd have the latitude to act as I see fit.

And it's worth mentioning, but I think not serious, that I don't see any of these as fun - I mention this only lightly, because I believe that I could
plausibly change this by becoming really invested in something and working hard on it - then it might be.  But on the other hand, we come to question 2:

Question 2:

On what grounds am I considering making this change - what is 'this change' and why?  For the sake of concreteness, let's say I want to become an "AI Safety Researcher".  It's possible it's something else like bio-safety stuff or some other EA-aligned thing or even something else entirely.  What good seems like it would come from this?  For one, I really enjoy the EA/LW community to a degree that just isn't true of anything else.  It's a group of people that natively speak my language without an accent, often better than I do, and I love it.  For another, the feeling of an ethical impulse I can't seem to adequately put off - realistically I essentially believe that they're right about biosafety and AI safety (though I'd have to do some research to confirm, if this were to be a decision-crux).  Further, it seems that, e.g., and especially AI safety is something that I find fundamentally interesting - 
maybe my actual intellectual calling.  I'm scared as to whether I'd be good at it - could I do work of quality similar to e.g. Byrnes or TurnTrout, etc.?  I think the answer is maybe - I might, especially if I work hard, be able to do really well; maybe not.  Remember in fact that my whole plan for QMAI, and Delft in general was based on an idiot version of "recognising phase transitions sounds a lot like intelligence" - that, whatever story I've passed around, that is basically why I went, however utterly misguided that turned out to be.  Studying Intelligence was what you wanted all-along - maybe not so much the alignment stuff, but they're damn closely related.  If I were to 'flip a coin' I'd know what I'm rooting for as soon as the coin is in the air.  But how consistent is this feeling?

Question 3:
Why then am I afraid to make this decision if it seems so one-sided?  That's the point - it shouldn't seem one-sided.  In particular, I think the decision-algorithm I'm using now is totally non-replicable - I know that my day-to-day opinions and feelings vary a lot, maybe a lot more than other people.  Point two for being concerned about the decision-algorithm is that I've been here before - I did the same thing moving into climate.  This suggests that I just don't have the right algorithm to make these decisions reliably and well.  Point three is this "do I want to sell my soul to EA" thing - my memetic independence from this movement is a) a source of immense pride and I think likely to be the source of a lot of development in my character, and b) tenuous at best.  On the other hand, speaking truthfully, I think that much of the hesitation comes from imagining a particular friend laughing a little bit at me - someone who I know has a better introsepctive, or at least planning-ahead, capacity than me.  If I were in the world where this really is just 'the grass is greener', I can say almoost for certain that the decision-algorithm wouldn't detect this, and I'd be bouncing around ad infinitum.  Are there some object-level things that I think are different in the climate-v-AI vs. Physics-v-climate?  At least maybe, but not clear if this is short-sightedness or what.
